{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IxxRGPOYw4lg",
        "outputId": "08dd3652-9b1a-4159-bb42-b36f7c781318"
      },
      "source": [
        "!curl -O https://maxhalford.github.io/files/datasets/creditcardfraud.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 65.9M  100 65.9M    0     0   114M      0 --:--:-- --:--:-- --:--:--  114M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uPtPCXSrxIUv",
        "outputId": "c219c95a-6d7e-4171-d23b-97385d18626b"
      },
      "source": [
        "! unzip creditcardfraud.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  creditcardfraud.zip\n",
            "replace creditcard.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNH03PpwxJMD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d72c5a8-5575-4cab-8e00-77ac39160f1d"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn import model_selection\n",
        "from scipy.misc import derivative\n",
        "import numpy as np\n",
        "import lightgbm\n",
        "from sklearn import metrics"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\n",
            "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "This will raise in a future version.\n",
            "\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "JGV7Ke0Vxkcu",
        "outputId": "810804b3-09c6-4dfa-faac-4218f0b85737"
      },
      "source": [
        "df = pd.read_csv('creditcard.csv')\n",
        "X = df.drop(columns='Class')\n",
        "y = df['Class']\n",
        "\n",
        "X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
        "    X, y,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "X_fit, X_val, y_fit, y_val = model_selection.train_test_split(\n",
        "    X_train, y_train,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "X_train.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           Time        V1        V2        V3        V4        V5        V6  \\\n",
              "83225   59741.0 -1.648591  1.228130  1.370169 -1.735542 -0.029455 -0.484129   \n",
              "52800   45648.0 -0.234775 -0.493269  1.236728 -2.338793 -1.176733  0.885733   \n",
              "21293   31579.0  1.134626 -0.774460 -0.163390 -0.533358 -0.604555 -0.244482   \n",
              "133600  80455.0  0.069514  1.017753  1.033117  1.384376  0.223233 -0.310845   \n",
              "38225   39302.0 -0.199441  0.610092 -0.114437  0.256565  2.290752  4.008475   \n",
              "\n",
              "              V7        V8        V9  ...       V20       V21       V22  \\\n",
              "83225   0.918645 -0.438750  0.982144  ...  0.384201 -0.218076 -0.203458   \n",
              "52800  -1.960981 -2.363412 -2.694774  ...  0.364679 -1.495358 -0.083066   \n",
              "21293  -0.212682  0.040782 -1.136627  ... -0.396476 -0.684454 -1.855269   \n",
              "133600  0.597287 -0.127658 -0.701533  ...  0.148760  0.097023  0.369957   \n",
              "38225  -0.123530  1.038374 -0.075846  ...  0.292972 -0.019733  0.165463   \n",
              "\n",
              "             V23       V24       V25       V26       V27       V28  Amount  \n",
              "83225  -0.213015  0.011372 -0.304481  0.632063 -0.262968 -0.099863   38.42  \n",
              "52800   0.074612 -0.347329  0.541900 -0.433294  0.089293  0.212029   61.20  \n",
              "21293   0.171997 -0.387783 -0.062985  0.245118 -0.061178  0.012180  110.95  \n",
              "133600 -0.219266 -0.124941 -0.049749 -0.112946  0.114440  0.066101   10.00  \n",
              "38225  -0.080978  1.020656 -0.300730 -0.269595  0.481769  0.254114   22.00  \n",
              "\n",
              "[5 rows x 30 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4eaabc1c-fab2-4094-8640-eb935a462033\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>...</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>83225</th>\n",
              "      <td>59741.0</td>\n",
              "      <td>-1.648591</td>\n",
              "      <td>1.228130</td>\n",
              "      <td>1.370169</td>\n",
              "      <td>-1.735542</td>\n",
              "      <td>-0.029455</td>\n",
              "      <td>-0.484129</td>\n",
              "      <td>0.918645</td>\n",
              "      <td>-0.438750</td>\n",
              "      <td>0.982144</td>\n",
              "      <td>...</td>\n",
              "      <td>0.384201</td>\n",
              "      <td>-0.218076</td>\n",
              "      <td>-0.203458</td>\n",
              "      <td>-0.213015</td>\n",
              "      <td>0.011372</td>\n",
              "      <td>-0.304481</td>\n",
              "      <td>0.632063</td>\n",
              "      <td>-0.262968</td>\n",
              "      <td>-0.099863</td>\n",
              "      <td>38.42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52800</th>\n",
              "      <td>45648.0</td>\n",
              "      <td>-0.234775</td>\n",
              "      <td>-0.493269</td>\n",
              "      <td>1.236728</td>\n",
              "      <td>-2.338793</td>\n",
              "      <td>-1.176733</td>\n",
              "      <td>0.885733</td>\n",
              "      <td>-1.960981</td>\n",
              "      <td>-2.363412</td>\n",
              "      <td>-2.694774</td>\n",
              "      <td>...</td>\n",
              "      <td>0.364679</td>\n",
              "      <td>-1.495358</td>\n",
              "      <td>-0.083066</td>\n",
              "      <td>0.074612</td>\n",
              "      <td>-0.347329</td>\n",
              "      <td>0.541900</td>\n",
              "      <td>-0.433294</td>\n",
              "      <td>0.089293</td>\n",
              "      <td>0.212029</td>\n",
              "      <td>61.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21293</th>\n",
              "      <td>31579.0</td>\n",
              "      <td>1.134626</td>\n",
              "      <td>-0.774460</td>\n",
              "      <td>-0.163390</td>\n",
              "      <td>-0.533358</td>\n",
              "      <td>-0.604555</td>\n",
              "      <td>-0.244482</td>\n",
              "      <td>-0.212682</td>\n",
              "      <td>0.040782</td>\n",
              "      <td>-1.136627</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.396476</td>\n",
              "      <td>-0.684454</td>\n",
              "      <td>-1.855269</td>\n",
              "      <td>0.171997</td>\n",
              "      <td>-0.387783</td>\n",
              "      <td>-0.062985</td>\n",
              "      <td>0.245118</td>\n",
              "      <td>-0.061178</td>\n",
              "      <td>0.012180</td>\n",
              "      <td>110.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>133600</th>\n",
              "      <td>80455.0</td>\n",
              "      <td>0.069514</td>\n",
              "      <td>1.017753</td>\n",
              "      <td>1.033117</td>\n",
              "      <td>1.384376</td>\n",
              "      <td>0.223233</td>\n",
              "      <td>-0.310845</td>\n",
              "      <td>0.597287</td>\n",
              "      <td>-0.127658</td>\n",
              "      <td>-0.701533</td>\n",
              "      <td>...</td>\n",
              "      <td>0.148760</td>\n",
              "      <td>0.097023</td>\n",
              "      <td>0.369957</td>\n",
              "      <td>-0.219266</td>\n",
              "      <td>-0.124941</td>\n",
              "      <td>-0.049749</td>\n",
              "      <td>-0.112946</td>\n",
              "      <td>0.114440</td>\n",
              "      <td>0.066101</td>\n",
              "      <td>10.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38225</th>\n",
              "      <td>39302.0</td>\n",
              "      <td>-0.199441</td>\n",
              "      <td>0.610092</td>\n",
              "      <td>-0.114437</td>\n",
              "      <td>0.256565</td>\n",
              "      <td>2.290752</td>\n",
              "      <td>4.008475</td>\n",
              "      <td>-0.123530</td>\n",
              "      <td>1.038374</td>\n",
              "      <td>-0.075846</td>\n",
              "      <td>...</td>\n",
              "      <td>0.292972</td>\n",
              "      <td>-0.019733</td>\n",
              "      <td>0.165463</td>\n",
              "      <td>-0.080978</td>\n",
              "      <td>1.020656</td>\n",
              "      <td>-0.300730</td>\n",
              "      <td>-0.269595</td>\n",
              "      <td>0.481769</td>\n",
              "      <td>0.254114</td>\n",
              "      <td>22.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 30 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4eaabc1c-fab2-4094-8640-eb935a462033')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4eaabc1c-fab2-4094-8640-eb935a462033 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4eaabc1c-fab2-4094-8640-eb935a462033');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1f50712e-b87e-4b4d-aa34-089c0f355a39\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1f50712e-b87e-4b4d-aa34-089c0f355a39')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1f50712e-b87e-4b4d-aa34-089c0f355a39 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "X_train"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "6hjasZP1zGJ_",
        "outputId": "fee0bd8b-1a47-4763-8aaf-6800abaa722b"
      },
      "source": [
        "y.value_counts()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Class\n",
              "0    284315\n",
              "1       492\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Class</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>284315</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>492</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDVPpvE4xq4T",
        "outputId": "a0d27925-0515-47d3-a4da-2fd41effb646"
      },
      "source": [
        "lgbtrain = lightgbm.Dataset(X_fit, y_fit)\n",
        "lgbeval = lightgbm.Dataset(X_val, y_val, reference=lgbtrain)\n",
        "\n",
        "model = lightgbm.train(\n",
        "    params={\n",
        "        'learning_rate': 0.01,\n",
        "        'objective': 'binary'\n",
        "    },\n",
        "    train_set=lgbtrain,\n",
        "    num_boost_round=100,\n",
        "    valid_sets=(lgbtrain, lgbeval),\n",
        "    valid_names=('fit', 'val'),\n",
        "    callbacks=[\n",
        "        lightgbm.early_stopping(stopping_rounds=20),\n",
        "    ],\n",
        ")\n",
        "\n",
        "y_proba = model.predict(X_test)\n",
        "y_pred = y_proba > 0.5"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 283, number of negative: 159920\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.103816 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 7650\n",
            "[LightGBM] [Info] Number of data points in the train set: 160203, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.001767 -> initscore=-6.336982\n",
            "[LightGBM] [Info] Start training from score -6.336982\n",
            "Training until validation scores don't improve for 20 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tfit's binary_logloss: 0.0018981\tval's binary_logloss: 0.0035569\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_AjlgEQdze2I",
        "outputId": "9d787d37-680a-4f75-ca31-58cd88db0ab2"
      },
      "source": [
        "print()\n",
        "print(f\"Test's ROC AUC: {metrics.roc_auc_score(y_test, y_proba):.5f}\")\n",
        "print(f\"Test's logloss: {metrics.log_loss(y_test, y_proba):.5f}\")\n",
        "print(f\"Test's average precision: {metrics.average_precision_score(y_test, y_proba):.5f}\")\n",
        "print(metrics.classification_report(y_test, y_pred))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test's ROC AUC: 0.96174\n",
            "Test's logloss: 0.00326\n",
            "Test's average precision: 0.85113\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     71089\n",
            "           1       0.94      0.64      0.76       113\n",
            "\n",
            "    accuracy                           1.00     71202\n",
            "   macro avg       0.97      0.82      0.88     71202\n",
            "weighted avg       1.00      1.00      1.00     71202\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5z9AIfWyeW7q"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9YY_Gfr3zvyr"
      },
      "source": [
        "Focal Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58eMgUf5xuIU"
      },
      "source": [
        "def focal_loss_lgb(y_pred, dtrain, alpha, gamma):\n",
        "\ta,g = alpha, gamma\n",
        "\ty_true = dtrain.label\n",
        "\tdef fl(x,t):\n",
        "\t\tp = 1/(1+np.exp(-x))\n",
        "\t\treturn -( a*t + (1-a)*(1-t) ) * (( 1 - ( t*p + (1-t)*(1-p)) )**g) * ( t*np.log(p)+(1-t)*np.log(1-p) )\n",
        "\tpartial_fl = lambda x: fl(x, y_true)\n",
        "\tgrad = derivative(partial_fl, y_pred, n=1, dx=1e-6)\n",
        "\thess = derivative(partial_fl, y_pred, n=2, dx=1e-6)\n",
        "\treturn grad, hess"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAcH0KNlx-KG"
      },
      "source": [
        "def focal_loss_lgb_eval_error(y_pred, dtrain, alpha, gamma):\n",
        "\ta,g = alpha, gamma\n",
        "\ty_true = dtrain.label\n",
        "\tp = 1/(1+np.exp(-y_pred))\n",
        "\tloss = -( a*y_true + (1-a)*(1-y_true) ) * (( 1 - ( y_true*p + (1-y_true)*(1-p)) )**g) * ( y_true*np.log(p)+(1-y_true)*np.log(1-p) )\n",
        "\treturn 'focal_loss', np.mean(loss), False"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNyShtqOx_kl",
        "outputId": "d94dd089-08d1-4e7b-bda8-4e2e30ba1ead"
      },
      "source": [
        "focal_loss = lambda x,y: focal_loss_lgb(x, y, 0.25, 1.)\n",
        "eval_error = lambda x,y: focal_loss_lgb_eval_error(x, y, 0.25, 1.)\n",
        "lgbtrain = lightgbm.Dataset(X_fit, y_fit, free_raw_data=True)\n",
        "lgbeval = lightgbm.Dataset(X_val, y_val)\n",
        "params  = {'learning_rate':0.1, 'num_boost_round':100, \"objective\": focal_loss}\n",
        "model = lightgbm.train(params, lgbtrain, valid_sets=[lgbeval], feval=eval_error, callbacks=[lightgbm.early_stopping(stopping_rounds=20),])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Using self-defined objective function\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.055804 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 7650\n",
            "[LightGBM] [Info] Number of data points in the train set: 160203, number of used features: 30\n",
            "[LightGBM] [Info] Using self-defined objective function\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-9de69f991ac0>:8: DeprecationWarning: scipy.misc.derivative is deprecated in SciPy v1.10.0; and will be completely removed in SciPy v1.12.0. You may consider using findiff: https://github.com/maroba/findiff or numdifftools: https://github.com/pbrod/numdifftools\n",
            "  grad = derivative(partial_fl, y_pred, n=1, dx=1e-6)\n",
            "<ipython-input-8-9de69f991ac0>:9: DeprecationWarning: scipy.misc.derivative is deprecated in SciPy v1.10.0; and will be completely removed in SciPy v1.12.0. You may consider using findiff: https://github.com/maroba/findiff or numdifftools: https://github.com/pbrod/numdifftools\n",
            "  hess = derivative(partial_fl, y_pred, n=2, dx=1e-6)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training until validation scores don't improve for 20 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[99]\tvalid_0's focal_loss: 0.000448057\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TW-RQUAAzosE"
      },
      "source": [
        "y_proba = model.predict(X_test)\n",
        "y_pred = y_proba > 0.5"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9LWyxrBDznN_",
        "outputId": "54c5dea0-691a-4b0e-8247-5a4f5371daaa"
      },
      "source": [
        "print()\n",
        "print(f\"Test's ROC AUC: {metrics.roc_auc_score(y_test, y_proba):.5f}\")\n",
        "print(f\"Test's logloss: {metrics.log_loss(y_test, y_proba):.5f}\")\n",
        "print(f\"Test's average precision: {metrics.average_precision_score(y_test, y_proba):.5f}\")\n",
        "print(metrics.classification_report(y_test, y_pred))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test's ROC AUC: 0.97893\n",
            "Test's logloss: 0.01433\n",
            "Test's average precision: 0.86107\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     71089\n",
            "           1       0.96      0.73      0.83       113\n",
            "\n",
            "    accuracy                           1.00     71202\n",
            "   macro avg       0.98      0.86      0.91     71202\n",
            "weighted avg       1.00      1.00      1.00     71202\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lightgbm.__version__"
      ],
      "metadata": {
        "id": "u5VHl2mlwhWZ",
        "outputId": "053e9d00-7b52-4d4f-f627-763d25def78e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'4.4.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usando API do Sklearn"
      ],
      "metadata": {
        "id": "BrLmpSnsgiS1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def focal_loss_lgb_sk(y_true, y_pred, alpha, gamma):\n",
        "    \"\"\"\n",
        "    Focal Loss for lightgbm\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    y_pred: numpy.ndarray\n",
        "        array with the predictions\n",
        "    dtrain: lightgbm.Dataset\n",
        "    alpha, gamma: float\n",
        "        See original paper https://arxiv.org/pdf/1708.02002.pdf\n",
        "    \"\"\"\n",
        "    global last_grad\n",
        "    global last_hess\n",
        "    a,g = alpha, gamma\n",
        "    def fl(x,t):\n",
        "        p = 1/(1+np.exp(-x))\n",
        "        return -( a*t + (1-a)*(1-t) ) * (( 1 - ( t*p + (1-t)*(1-p)) )**g) * ( t*np.log(p)+(1-t)*np.log(1-p) )\n",
        "    partial_fl = lambda x: fl(x, y_true)\n",
        "    grad = derivative(partial_fl, y_pred, n=1, dx=1e-6)\n",
        "    hess = derivative(partial_fl, y_pred, n=2, dx=1e-6)\n",
        "    return grad, hess"
      ],
      "metadata": {
        "id": "BiTcP9rcgkfy"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def focal_loss_lgb_eval_error_sk(y_true, y_pred, alpha, gamma):\n",
        "    \"\"\"\n",
        "    Adapation of the Focal Loss for lightgbm to be used as evaluation loss\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    y_pred: numpy.ndarray\n",
        "        array with the predictions\n",
        "    dtrain: lightgbm.Dataset\n",
        "    alpha, gamma: float\n",
        "        See original paper https://arxiv.org/pdf/1708.02002.pdf\n",
        "    \"\"\"\n",
        "    a,g = alpha, gamma\n",
        "    p = 1/(1+np.exp(-y_pred))\n",
        "    loss = -( a*y_true + (1-a)*(1-y_true) ) * (( 1 - ( y_true*p + (1-y_true)*(1-p)) )**g) * ( y_true*np.log(p)+(1-y_true)*np.log(1-p) )\n",
        "    return 'focal_loss', np.mean(loss), False"
      ],
      "metadata": {
        "id": "LcCTosyZgljf"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "focal_loss = lambda x,y: focal_loss_lgb_sk(x, y, 0.25, 2.)\n",
        "eval_error = lambda x,y: focal_loss_lgb_eval_error_sk(x, y, 0.25, 2.)\n",
        "model = lightgbm.LGBMClassifier(objective=focal_loss, learning_rate=0.1, num_boost_round=100, early_stopping_rounds=20, verbose = 0)\n",
        "model.fit(\n",
        "    X_fit,\n",
        "    y_fit,\n",
        "    eval_set=[(X_val, y_val)],\n",
        "    eval_metric=eval_error)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "id": "vB7l9kSjgmx-",
        "outputId": "bc621d49-f7ab-4855-abd5-a6ffd1f8a4fb"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] early_stopping_round is set=20, early_stopping_rounds=20 will be ignored. Current value: early_stopping_round=20\n",
            "[LightGBM] [Warning] num_iterations is set=100, num_boost_round=100 will be ignored. Current value: num_iterations=100\n",
            "[LightGBM] [Warning] early_stopping_round is set=20, early_stopping_rounds=20 will be ignored. Current value: early_stopping_round=20\n",
            "[LightGBM] [Warning] num_iterations is set=100, num_boost_round=100 will be ignored. Current value: num_iterations=100\n",
            "[LightGBM] [Info] Using self-defined objective function\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-1652dbc51a81>:20: DeprecationWarning: scipy.misc.derivative is deprecated in SciPy v1.10.0; and will be completely removed in SciPy v1.12.0. You may consider using findiff: https://github.com/maroba/findiff or numdifftools: https://github.com/pbrod/numdifftools\n",
            "  grad = derivative(partial_fl, y_pred, n=1, dx=1e-6)\n",
            "<ipython-input-14-1652dbc51a81>:21: DeprecationWarning: scipy.misc.derivative is deprecated in SciPy v1.10.0; and will be completely removed in SciPy v1.12.0. You may consider using findiff: https://github.com/maroba/findiff or numdifftools: https://github.com/pbrod/numdifftools\n",
            "  hess = derivative(partial_fl, y_pred, n=2, dx=1e-6)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LGBMClassifier(early_stopping_rounds=20, num_boost_round=100,\n",
              "               objective=<function <lambda> at 0x7f34f9796dd0>, verbose=0)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(early_stopping_rounds=20, num_boost_round=100,\n",
              "               objective=&lt;function &lt;lambda&gt; at 0x7f34f9796dd0&gt;, verbose=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(early_stopping_rounds=20, num_boost_round=100,\n",
              "               objective=&lt;function &lt;lambda&gt; at 0x7f34f9796dd0&gt;, verbose=0)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_proba = model.predict_proba(X_test)\n",
        "y_pred = y_proba > 0.5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUo00fBOgn9K",
        "outputId": "4f17e09f-4c33-432c-b9b1-6b9420b85091"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:1346: UserWarning: Cannot compute class probabilities or labels due to the usage of customized objective function.\n",
            "Returning raw scores instead.\n",
            "  _log_warning(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print()\n",
        "print(f\"Test's ROC AUC: {metrics.roc_auc_score(y_test, y_proba):.5f}\")\n",
        "print(f\"Test's logloss: {metrics.log_loss(y_test, y_proba):.5f}\")\n",
        "print(f\"Test's average precision: {metrics.average_precision_score(y_test, y_proba):.5f}\")\n",
        "print(metrics.classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1yrjhe91g8pl",
        "outputId": "c5b1f55a-05a9-48be-cdd5-5d40b851a73d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test's ROC AUC: 0.97736\n",
            "Test's logloss: 0.01397\n",
            "Test's average precision: 0.86956\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     71089\n",
            "           1       0.95      0.70      0.81       113\n",
            "\n",
            "    accuracy                           1.00     71202\n",
            "   macro avg       0.98      0.85      0.90     71202\n",
            "weighted avg       1.00      1.00      1.00     71202\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Regression"
      ],
      "metadata": {
        "id": "VHNrWn9Tl8SI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_diabetes"
      ],
      "metadata": {
        "id": "xEZrD4O_l88x"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_diabetes()"
      ],
      "metadata": {
        "id": "POql0H3Xl-rd"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LzkoEvhImAjV",
        "outputId": "97a005db-f6f3-4505-e662-33d10ad2aad4"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['data', 'target', 'frame', 'DESCR', 'feature_names', 'data_filename', 'target_filename', 'data_module'])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
        "    dataset['data'], dataset['target'],\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "X_fit, X_val, y_fit, y_val = model_selection.train_test_split(\n",
        "    X_train, y_train,\n",
        "    random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "dNyaBLtomBVz"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "last_grad = None\n",
        "last_hess = None\n",
        "\n",
        "def objective_ls(y_true, y_pred):\n",
        "  global last_grad\n",
        "  global last_hess\n",
        "  grad = (y_pred - y_true)\n",
        "  hess = np.ones(len(y_true))\n",
        "\n",
        "  alpha = 0.98\n",
        "  lamb = 2\n",
        "\n",
        "  if last_grad is not None:\n",
        "    for n in range(len(grad)):\n",
        "      last_grad[n] = last_grad[n] * alpha + grad[n] * (1 - alpha)\n",
        "      grad[n] = grad[n] + last_grad[n] * lamb\n",
        "\n",
        "    for n in range(len(grad)):\n",
        "      last_hess[n] = last_hess[n] * alpha + hess[n] * (1 - alpha)\n",
        "      hess[n] = hess[n] + last_hess[n] * lamb\n",
        "  else:\n",
        "    last_grad = grad\n",
        "    last_hess = hess\n",
        "  return grad, hess\n",
        "\n",
        "def absolute_error_obj(alpha):\n",
        "    def absolute_error(labels, predt):\n",
        "        alpha_grok = 0.98\n",
        "        lamb = 2.0\n",
        "        global last_grad\n",
        "        global last_hess\n",
        "        x = predt - labels\n",
        "        grad = np.sign(x)\n",
        "        grad[np.abs(x) < alpha] = 2/alpha*x[np.abs(x) < alpha]\n",
        "        hess = np.zeros_like(labels)\n",
        "        hess[np.abs(x) < alpha] = 2/alpha\n",
        "        if last_grad is not None:\n",
        "          for n in range(len(grad)):\n",
        "            last_grad[n] = last_grad[n] * alpha_grok + grad[n] * (1 - alpha_grok)\n",
        "            grad[n] = grad[n] + last_grad[n] * lamb\n",
        "\n",
        "          for n in range(len(grad)):\n",
        "            last_hess[n] = last_hess[n] * alpha_grok + hess[n] * (1 - alpha_grok)\n",
        "            hess[n] = hess[n] + last_hess[n] * lamb\n",
        "        else:\n",
        "          last_grad = grad\n",
        "          last_hess = hess\n",
        "        return grad, hess\n",
        "    return absolute_error"
      ],
      "metadata": {
        "id": "QUA7pOSmtNiP"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error as mae\n",
        "from lightgbm import LGBMRegressor\n",
        "\n",
        "# Create an instance of the LightGBM Regressor with the RMSE metric.\n",
        "model = LGBMRegressor(objective=objective_ls, num_iterations=100, early_stopping_rounds=20)\n",
        "\n",
        "# Train the model using the training data.\n",
        "model.fit(X_train, y_train, eval_set=[(X_val, y_val)],\n",
        "    eval_metric='mae')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 932
        },
        "id": "rtrdOYe2mxYe",
        "outputId": "581bf4da-7e19-4164-d1d5-67f47b9c5120"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] early_stopping_round is set=20, early_stopping_rounds=20 will be ignored. Current value: early_stopping_round=20\n",
            "[LightGBM] [Info] Using self-defined objective function\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000087 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 569\n",
            "[LightGBM] [Info] Number of data points in the train set: 331, number of used features: 10\n",
            "[LightGBM] [Warning] early_stopping_round is set=20, early_stopping_rounds=20 will be ignored. Current value: early_stopping_round=20\n",
            "[LightGBM] [Info] Using self-defined objective function\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training until validation scores don't improve for 20 rounds\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Early stopping, best iteration is:\n",
            "[14]\tvalid_0's l1: 40.4195\tvalid_0's l2: 2472.98\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LGBMRegressor(early_stopping_rounds=20, num_iterations=100,\n",
              "              objective=<function objective_ls at 0x7f34f49af520>)"
            ],
            "text/html": [
              "<style>#sk-container-id-12 {color: black;}#sk-container-id-12 pre{padding: 0;}#sk-container-id-12 div.sk-toggleable {background-color: white;}#sk-container-id-12 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-12 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-12 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-12 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-12 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-12 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-12 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-12 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-12 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-12 div.sk-item {position: relative;z-index: 1;}#sk-container-id-12 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-12 div.sk-item::before, #sk-container-id-12 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-12 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-12 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-12 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-12 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-12 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-12 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-12 div.sk-label-container {text-align: center;}#sk-container-id-12 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-12 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMRegressor(early_stopping_rounds=20, num_iterations=100,\n",
              "              objective=&lt;function objective_ls at 0x7f34f49af520&gt;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" checked><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMRegressor</label><div class=\"sk-toggleable__content\"><pre>LGBMRegressor(early_stopping_rounds=20, num_iterations=100,\n",
              "              objective=&lt;function objective_ls at 0x7f34f49af520&gt;)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the training and validation data.\n",
        "y_pred_train = model.predict(X_train)\n",
        "y_pred_val = model.predict(X_val)\n",
        "y_pred_test = model.predict(X_test)"
      ],
      "metadata": {
        "id": "zszn_ef3na1n"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training MAE: \", mae(y_train, y_pred_train))\n",
        "print(\"Validation MAE: \", mae(y_val, y_pred_val))\n",
        "print(\"Test MAE: \", mae(y_test, y_pred_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BilbQKGMnMWG",
        "outputId": "26a22e2d-68cc-41ba-dd9d-3cd7253ebfca"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training MAE:  41.68382805369672\n",
            "Validation MAE:  40.419457303439295\n",
            "Test MAE:  44.44888225434529\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training MAE:  17.427838170721184\n",
        "Validation MAE:  17.26335546741846\n",
        "Test MAE:  44.062678849463346"
      ],
      "metadata": {
        "id": "YXIucOir_TjM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Grokfast"
      ],
      "metadata": {
        "id": "qQJGSxSzqeL9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import deque\n",
        "from typing import Dict, Optional, Literal\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "def gradfilter_ma(\n",
        "    m: nn.Module,\n",
        "    grads: Optional[Dict[str, deque]] = None,\n",
        "    window_size: int = 100,\n",
        "    lamb: float = 5.0,\n",
        "    filter_type: Literal['mean', 'sum'] = 'mean',\n",
        "    warmup: bool = True,\n",
        "    trigger: bool = False, # For ablation study.\n",
        ") -> Dict[str, deque]:\n",
        "    if grads is None:\n",
        "        grads = {n: deque(maxlen=window_size) for n, p in m.named_parameters() if p.requires_grad and p.grad is not None}\n",
        "\n",
        "    for n, p in m.named_parameters():\n",
        "        if p.requires_grad and p.grad is not None:\n",
        "            grads[n].append(p.grad.data.detach()) # .cpu())\n",
        "\n",
        "            # Modify the gradients.\n",
        "            if not warmup or len(grads[n]) == window_size and not trigger:\n",
        "                if filter_type == \"mean\":\n",
        "                    avg = sum(grads[n]) / len(grads[n])\n",
        "                elif filter_type == \"sum\":\n",
        "                    avg = sum(grads[n])\n",
        "                else:\n",
        "                    raise ValueError(f\"Unrecognized filter_type {filter_type}\")\n",
        "                p.grad.data = p.grad.data + avg * lamb\n",
        "\n",
        "    return grads\n",
        "\n",
        "\n",
        "def gradfilter_ema(\n",
        "    m: nn.Module,\n",
        "    grads: Optional[Dict[str, torch.Tensor]] = None,\n",
        "    alpha: float = 0.98,\n",
        "    lamb: float = 2.0,\n",
        ") -> Dict[str, torch.Tensor]:\n",
        "    if grads is None:\n",
        "        grads = {n: p.grad.data.detach() for n, p in m.named_parameters() if p.requires_grad and p.grad is not None}\n",
        "\n",
        "    for n, p in m.named_parameters():\n",
        "        if p.requires_grad and p.grad is not None:\n",
        "            grads[n] = grads[n] * alpha + p.grad.data.detach() * (1 - alpha)\n",
        "            p.grad.data = p.grad.data + grads[n] * lamb\n",
        "\n",
        "    return grads"
      ],
      "metadata": {
        "id": "Xbo6fegXqdg9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pytorch Model"
      ],
      "metadata": {
        "id": "26paRzhwpHHx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "sizes = [X_train[0].shape[0], X_train[0].shape[0]*4, X_train[0].shape[0]*2, X_train[0].shape[0], 1]\n",
        "\n",
        "# Define the model\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(sizes[0], sizes[1]),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(sizes[1], sizes[2]),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(sizes[2], sizes[3]),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(sizes[3], sizes[4])\n",
        ")"
      ],
      "metadata": {
        "id": "Nw_FC3ZUpIJv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# loss function and optimizer\n",
        "loss_fn = nn.L1Loss()  # mean absolute error\n",
        "optimizer = optim.AdamW(model.parameters(), lr=0.0001)"
      ],
      "metadata": {
        "id": "JiY-_t8hpOzr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "import copy\n",
        "\n",
        "# train-test split of the dataset\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.float32).reshape(-1, 1)\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test = torch.tensor(y_test, dtype=torch.float32).reshape(-1, 1)\n",
        "\n",
        "# training parameters\n",
        "n_epochs = 1000   # number of epochs to run\n",
        "batch_size = 64  # size of each batch\n",
        "batch_start = torch.arange(0, len(X_train), batch_size)\n",
        "\n",
        "# Hold the best model\n",
        "best_mae = np.inf   # init to infinity\n",
        "best_weights = None\n",
        "history = []\n",
        "grads = None\n",
        "\n",
        "# training loop\n",
        "for epoch in range(n_epochs):\n",
        "    model.train()\n",
        "    with tqdm.tqdm(batch_start, unit=\"batch\", mininterval=0, disable=True) as bar:\n",
        "        bar.set_description(f\"Epoch {epoch}\")\n",
        "        for start in bar:\n",
        "            # take a batch\n",
        "            X_batch = X_train[start:start+batch_size]\n",
        "            y_batch = y_train[start:start+batch_size]\n",
        "            # forward pass\n",
        "            y_pred = model(X_batch)\n",
        "            loss = loss_fn(y_pred, y_batch)\n",
        "            # backward pass\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "\n",
        "            grads = gradfilter_ema(model, grads=grads)\n",
        "            # update weights\n",
        "            optimizer.step()\n",
        "            # print progress\n",
        "            bar.set_postfix(mae=float(loss))\n",
        "    # evaluate accuracy at end of each epoch\n",
        "    model.eval()\n",
        "    y_pred = model(X_test)\n",
        "    mae = loss_fn(y_pred, y_test)\n",
        "    mae = float(mae)\n",
        "    history.append(mae)\n",
        "    if mae < best_mae:\n",
        "        best_mae = mae\n",
        "        best_weights = copy.deepcopy(model.state_dict())\n",
        "\n",
        "# restore model and return best accuracy\n",
        "model.load_state_dict(best_weights)"
      ],
      "metadata": {
        "id": "s-FxdgOApUeY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "print(\"MAE: %.2f\" % best_mae)\n",
        "plt.plot(history)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "APUfFq-XpgdK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rW1uS12Jp0zb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}